{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5b46f3",
   "metadata": {},
   "source": [
    "# Hybrid Keyword Matching - Aho-Corasick Algorithm\n",
    "\n",
    "This notebook implements a hybrid keyword matching approach for efficient transaction categorization using the Aho-Corasick algorithm for multi-pattern string matching.\n",
    "\n",
    "## Key Features\n",
    "- **Dual Matching Strategy**: \n",
    "  - Token-based matching for short keywords (< 4 characters)\n",
    "  - Aho-Corasick automaton for long keywords (>= 4 characters)\n",
    "- **Efficient Performance**: O(n + z) complexity where n is text length and z is matches\n",
    "- **Category Scoring**: Aggregates keyword matches weighted by frequency scores\n",
    "- **Scalable**: Optimized for large datasets with many keywords\n",
    "\n",
    "## Performance Metrics\n",
    "- Counts matches against actual categories\n",
    "- Calculates accuracy of predictions\n",
    "- Identifies true positives and misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4a1dc-c80f-497a-9043-af5d808591fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd  # Data manipulation\n",
    "import numpy as np   # Numerical computations\n",
    "import re            # Regular expression processing\n",
    "from collections import Counter  # Counting keyword matches\n",
    "import ahocorasick   # Efficient multi-pattern string matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed06047-6227-407a-bf96-7db33f4690fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load debit transaction data\n",
    "df = pd.read_excel(\"debit_txn_v5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143c476-517e-4a3c-9f1d-41819e544641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \"\"\"\n",
    "    Normalize narration text for consistent matching.\n",
    "    \n",
    "    Steps:\n",
    "    1. Lowercase conversion\n",
    "    2. Remove special characters\n",
    "    3. Collapse multiple spaces\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw narration\n",
    "        \n",
    "    Returns:\n",
    "        str: Normalized text\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z0-9 ]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76324fe3-e1ec-4fe2-8013-a92c429b950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to all narrations\n",
    "df[\"narr_norm\"] = df[\"Narration\"].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594833f-8e44-4e6b-8115-f58f03450008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keyword frequency data with category labels\n",
    "# This file contains keywords, their categories, and frequency scores\n",
    "kw_df = pd.read_excel(\"clean_keyword_frequency_by_category_debit.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9bb8f4-6e4c-409c-91a6-88839a02e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize normalized narrations by splitting on whitespace\n",
    "# This creates a list of words for token-based matching\n",
    "df['tokens'] = (\n",
    "    df['narr_norm']\n",
    "    .fillna('')\n",
    "    .str.lower()\n",
    "    .str.split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46a419-3799-432e-a9d6-827fce218e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare narration strings (remove spaces for substring matching)\n",
    "df[\"narr_str\"] = (\n",
    "    df[\"narr_norm\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"\", regex=False)  # Remove spaces for continuous matching\n",
    ")\n",
    "\n",
    "# Prepare keyword strings (remove spaces for matching)\n",
    "kw_df = kw_df.dropna(subset=[\"keyword\"])  # Remove keywords with missing values\n",
    "\n",
    "kw_df[\"keyword_str\"] = (\n",
    "    kw_df[\"keyword\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"\", regex=False)  # Normalize keyword strings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccb481-9aad-4ba4-a6c8-1b961991ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique categories from keyword dataframe\n",
    "categories = kw_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464f868-e77c-4f90-b412-8e4df774b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square the scores for increased weighting of high-frequency keywords\n",
    "# This emphasizes more significant keywords in the matching process\n",
    "kw_df['score_sq'] = kw_df['score'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833df4e0-4939-43a9-82bc-0b81ab052f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build two separate lookup structures for different keyword lengths\n",
    "# Strategy: Use different matching approaches based on keyword length\n",
    "\n",
    "# Short keywords (< 4 chars): Use token-based matching\n",
    "short_kw_mask = kw_df['keyword'].str.len() < 4\n",
    "kw_lookup_short = (\n",
    "    kw_df[short_kw_mask]\n",
    "    .set_index(['keyword', 'category'])['score_sq']\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Long keywords (>= 4 chars): Use Aho-Corasick automaton for efficient matching\n",
    "long_kw_df = kw_df[~short_kw_mask]\n",
    "\n",
    "def build_long_category_automaton(df_long):\n",
    "    \"\"\"\n",
    "    Build Aho-Corasick automaton for efficient multi-pattern matching.\n",
    "    \n",
    "    Args:\n",
    "        df_long (DataFrame): Keywords with length >= 4\n",
    "        \n",
    "    Returns:\n",
    "        ahocorasick.Automaton: Compiled automaton ready for matching\n",
    "    \"\"\"\n",
    "    automaton = ahocorasick.Automaton()\n",
    "    for _, row in df_long.iterrows():\n",
    "        kw = str(row[\"keyword\"]).lower()\n",
    "        cat = row[\"category\"]\n",
    "        score_sq = row[\"score\"] ** 2\n",
    "        # Each keyword maps to (category, score) for later aggregation\n",
    "        automaton.add_word(kw, (cat, score_sq))\n",
    "    automaton.make_automaton()  # Compile automaton\n",
    "    return automaton\n",
    "\n",
    "long_automaton = build_long_category_automaton(long_kw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e075875-7f70-4e32-a01d-967f72059a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_check(tokens):\n",
    "    \"\"\"\n",
    "    Check tokens against keyword list (used for validation).\n",
    "    \n",
    "    Args:\n",
    "        tokens (list): List of word tokens\n",
    "        \n",
    "    Returns:\n",
    "        Counter: Category scores based on token matches\n",
    "    \"\"\"\n",
    "    scores = Counter()\n",
    "    for t in tokens:\n",
    "        for cat in categories:\n",
    "            val = kw_lookup.get((t, cat), 0)\n",
    "            if val > 0:\n",
    "                scores[cat] += val\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1eaa7d-f9a0-4448-8a31-a0bec878f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_score(row):\n",
    "    \"\"\"\n",
    "    Calculate category scores using hybrid matching approach.\n",
    "    \n",
    "    Combines:\n",
    "    1. Token-based matching for short keywords\n",
    "    2. Aho-Corasick matching for long keywords\n",
    "    \n",
    "    Args:\n",
    "        row (Series): Transaction row with narration data\n",
    "        \n",
    "    Returns:\n",
    "        Counter: Category scores aggregated from all matches\n",
    "    \"\"\"\n",
    "    scores = Counter()\n",
    "    narr_norm = row[\"narr_norm\"]\n",
    "    tokens = row[\"tokens\"]\n",
    "    \n",
    "    # 1. Token-based matching for short keywords\n",
    "    for t in tokens:\n",
    "        for cat in categories:\n",
    "            val = kw_lookup_short.get((t, cat), 0)\n",
    "            if val > 0:\n",
    "                scores[cat] += val\n",
    "    \n",
    "    # 2. Aho-Corasick matching for long keywords\n",
    "    for _, (cat, score_sq) in long_automaton.iter(narr_norm.lower()):\n",
    "        scores[cat] += score_sq\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e88c1-5633-42b1-ae76-80aa157ee25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hybrid scoring to all transactions\n",
    "results = df.apply(hybrid_score, axis=1)\n",
    "scores_df = pd.DataFrame(results.tolist()).fillna(0)\n",
    "# Take square root to reverse the squaring done earlier (normalize scores)\n",
    "scores_df = np.sqrt(scores_df)\n",
    "\n",
    "# Concatenate scores with original dataframe\n",
    "df = pd.concat([df, scores_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95bfcb3-08a6-47cd-b400-f311805db675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict category as the one with highest score\n",
    "df[\"predicted_category\"] = scores_df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7067a3-2c5c-4952-9864-dab86c28c149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(86960)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy: count matching predictions (case-insensitive)\n",
    "(df['Category'].str.strip().str.lower() == df['predicted_category'].str.strip().str.lower()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62866417-8e93-41d6-a568-46c44599b1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(113484)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total transactions analyzed\n",
    "df[\"Category\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1934bf-b732-47c4-ad1e-c577c3b6348b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
